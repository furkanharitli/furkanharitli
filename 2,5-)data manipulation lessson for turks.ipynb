{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ilk konumuz eksik verlileri basit bir şekilde doldurmak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri=pd.read_csv(\"eksikveriler.csv\")\n",
    "boy=veri[\"boy\"]\n",
    "kilo=veri[\"kilo\"]\n",
    "yas=veri[\"yas\"]\n",
    "ulke=veri[\"ulke\"]\n",
    "cins=veri[\"cinsiyet\"]\n",
    "boykilo=[[\"boy\"],[\"kilo\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* simpleimputer bu işte baya işimize yarayacak bir kütüphanedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*missing_values ile hedef alınan kısmı seçiyoruz sonrada nasıl yapacağımıza strateji ile karar veriyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer=SimpleImputer(missing_values=np.nan,strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ilk olarad 1 ve 4. kolonlar arasındaki sayısal verileri alalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yas=veri.iloc[:,1:4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*sonra bu Yas verisini bilgisayarın öğrenmesi için imputere fit ettirticez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer=imputer.fit(Yas[:,1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*daha sonra imputere transform ettirterek öğrendiklerini uygulattırtıcaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130.    30.    10.  ]\n",
      " [125.    36.    11.  ]\n",
      " [135.    34.    10.  ]\n",
      " [133.    30.     9.  ]\n",
      " [129.    38.    12.  ]\n",
      " [180.    90.    30.  ]\n",
      " [190.    80.    25.  ]\n",
      " [175.    90.    35.  ]\n",
      " [177.    60.    22.  ]\n",
      " [185.   105.    33.  ]\n",
      " [165.    55.    27.  ]\n",
      " [155.    50.    44.  ]\n",
      " [160.    58.    28.45]\n",
      " [162.    59.    41.  ]\n",
      " [167.    62.    55.  ]\n",
      " [174.    70.    47.  ]\n",
      " [193.    90.    28.45]\n",
      " [187.    80.    27.  ]\n",
      " [183.    88.    28.  ]\n",
      " [159.    40.    29.  ]\n",
      " [164.    66.    32.  ]\n",
      " [166.    56.    42.  ]]\n"
     ]
    }
   ],
   "source": [
    "Yas[:,1:4]=imputer.transform(Yas[:,1:4])\n",
    "print(Yas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 SEÇENEKLİ VERİLERİ MAKİNENİN ANLAYACAĞI ŞEKLE ,0 VE 1 HALİNDE KATEGORİZE ETMEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulke=veri.iloc[:,0:1].values\n",
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "ulke[:,0]=le.fit_transform(veri.iloc[:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*labelencoder verileri sayıya çevirir ilk denk gelene 1 ikincisine 2 3. denk gelene 2 son denk gelen ifadeye de 0 verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(ulke)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*onehotencodder ise her değeri yeni birer kolon haline getirerek eğer fransızsa fr ye 1 geri kalana 0 verdirttirir\n",
    "\n",
    "*bu yöntemler bize kategorik verileri sayısal veriye dönüştürmeyi sağlarlar dolayısı ile ilerki aşamada çok işimize yararlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ohe=preprocessing.OneHotEncoder()\n",
    "ulke=ohe.fit_transform(ulke).toarray()\n",
    "print(ulke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERİLERİ BİRLEŞTİRMEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr  usa\n",
      "0   0.0  1.0  0.0\n",
      "1   0.0  1.0  0.0\n",
      "2   0.0  1.0  0.0\n",
      "3   0.0  1.0  0.0\n",
      "4   0.0  1.0  0.0\n",
      "5   0.0  1.0  0.0\n",
      "6   0.0  1.0  0.0\n",
      "7   0.0  1.0  0.0\n",
      "8   0.0  1.0  0.0\n",
      "9   0.0  0.0  1.0\n",
      "10  0.0  0.0  1.0\n",
      "11  0.0  0.0  1.0\n",
      "12  0.0  0.0  1.0\n",
      "13  0.0  0.0  1.0\n",
      "14  0.0  0.0  1.0\n",
      "15  1.0  0.0  0.0\n",
      "16  1.0  0.0  0.0\n",
      "17  1.0  0.0  0.0\n",
      "18  1.0  0.0  0.0\n",
      "19  1.0  0.0  0.0\n",
      "20  1.0  0.0  0.0\n",
      "21  1.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "sonuc=pd.DataFrame(columns=[\"fr\",\"tr\",\"usa\"],data=ulke)\n",
    "print(sonuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr  usa    boy   kilo    yas cinsiyet\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00        e\n",
      "1   0.0  1.0  0.0  125.0   36.0  11.00        e\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00        k\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00        k\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00        e\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00        e\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00        e\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00        e\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00        k\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00        e\n",
      "10  0.0  0.0  1.0  165.0   55.0  27.00        k\n",
      "11  0.0  0.0  1.0  155.0   50.0  44.00        k\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45        k\n",
      "13  0.0  0.0  1.0  162.0   59.0  41.00        k\n",
      "14  0.0  0.0  1.0  167.0   62.0  55.00        k\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00        e\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45        e\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00        e\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00        e\n",
      "19  1.0  0.0  0.0  159.0   40.0  29.00        k\n",
      "20  1.0  0.0  0.0  164.0   66.0  32.00        k\n",
      "21  1.0  0.0  0.0  166.0   56.0  42.00        k\n"
     ]
    }
   ],
   "source": [
    "sonuc2=pd.DataFrame(data=Yas,columns=[\"boy\",\"kilo\",\"yas\"])\n",
    "sonuc3=pd.DataFrame(data=cins,columns=[\"cinsiyet\"])\n",
    "sons=pd.concat([sonuc,sonuc2],axis=1)\n",
    "sonsonuc=pd.concat([sons,sonuc3],axis=1)\n",
    "print(sonsonuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,ytrain,y_test=train_test_split(sons,sonuc3,test_size=0.30,random_state=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "694b30b78a0f9ee6468ff63ae8bc281eebfaa5f5677d8f8b6c6a215cacf47117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
